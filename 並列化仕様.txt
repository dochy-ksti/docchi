KVal::Bit(0)をあらかじめ、全部のMListの最初の方に入れる。0の場合並列化なし
1アイテムごとに何KVal使っているか数えながら、KValリストを作り上げていく。
ある定数（多分1万ぐらい）のKValを1タスクにして、スレッドに分割していく。
アイテムごとに、定数を超えたらタスク分割。1タスクに属するアイテム数は1か2か3かわからないが、中途半端なところでは分割しない。
分割が発生したら、KVal::Bitの部分を上書きする。KVal::Binaryのdocchi_compaction形式で、
スレッド数、1スレッドのアイテム数*スレッド数。
ここが1万ぐらいになってしまうと、compactionの解析に時間がかかるようになってくるが・・・まあどうでもいいか

問題は、10000が大きすぎてテストしづれえなってこと。まあそれもいいや。
実践の中で大きいデータが出来るはずだから、それをテストデータにする。それまでこれの実装は待つ。

あとはcompactionの並列化。最初からやっておくべきだったのでは？
ある定数個(多分10000ぐらい)のKValに分割し、それぞれのcompactionバイナリを作る。
最初に分割数とタスクごとのバイト数を入れる。
ファイルを分割したバイナリのバイト数だけ読み出し、スレッドに送って解析させる。
読み出しにかかる時間と、解析の時間を並列化させられる。
実はSSDは（HDDの直列読み出しも)十分に早いので、読出しよりも解析がオーバーヘッドになる
（特にdocchi_compactionはビット単位で保存するので読み出しよりも解析の時間がかかる)。

これも問題は大きなテストデータが必要になること。
同じ理由で、実装は実践データが揃うまで待つ。